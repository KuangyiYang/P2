{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Student Intervention System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student data read successfully!\n"
     ]
    }
   ],
   "source": [
    "# Read student data\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print \"Student data read successfully!\"\n",
    "# Note: The last column 'passed' is the target/label, all other are feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you find out the following facts about the dataset?\n",
    "- Total number of students\n",
    "- Number of students who passed\n",
    "- Number of students who failed\n",
    "- Graduation rate of the class (%)\n",
    "- Number of features\n",
    "\n",
    "_Use the code block below to compute these values. Instructions/steps are marked using **TODO**s._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
       "\n",
       "   ...   internet romantic  famrel  freetime  goout Dalc Walc health absences  \\\n",
       "0  ...         no       no       4         3      4    1    1      3        6   \n",
       "1  ...        yes       no       5         3      3    1    1      3        4   \n",
       "2  ...        yes       no       4         3      2    2    3      3       10   \n",
       "3  ...        yes      yes       3         2      2    1    1      5        2   \n",
       "4  ...         no       no       4         3      2    1    2      5        4   \n",
       "\n",
       "  passed  \n",
       "0     no  \n",
       "1     no  \n",
       "2    yes  \n",
       "3    yes  \n",
       "4    yes  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Number of features: 30\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# Compute desired values - replace each '?' with an appropriate expression/function call\n",
    "n_students = student_data.shape[0]\n",
    "n_features = student_data.shape[1] - 1\n",
    "n_passed = student_data[student_data['passed'] == 'yes'].shape[0]\n",
    "n_failed = student_data[student_data['passed'] == 'no'].shape[0]\n",
    "grad_rate = np.true_divide(n_passed, n_students)*100\n",
    "print \"Total number of students: {}\".format(n_students)\n",
    "print \"Number of students who passed: {}\".format(n_passed)\n",
    "print \"Number of students who failed: {}\".format(n_failed)\n",
    "print \"Number of features: {}\".format(n_features)\n",
    "print \"Graduation rate of the class: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):-\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "Target column: passed\n",
      "\n",
      "Feature values:-\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(student_data.columns[:-1])  # all columns but last are features\n",
    "target_col = student_data.columns[-1]  # last column is the target/label\n",
    "print \"Feature column(s):-\\n{}\".format(feature_cols)\n",
    "print \"Target column: {}\".format(target_col)\n",
    "\n",
    "X_all = student_data[feature_cols]  # feature values for all students\n",
    "y_all = student_data[target_col]  # corresponding targets/labels\n",
    "print \"\\nFeature values:-\"\n",
    "print X_all.head()  # print the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48):-\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)  # e.g. 'school' => 'school_GP', 'school_MS'\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "\n",
    "    return outX\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 300 samples\n",
      "Test set: 95 samples\n"
     ]
    }
   ],
   "source": [
    "# decide how many training vs test samples \n",
    "num_all = student_data.shape[0]  # same as len(student_data)\n",
    "num_train = 300  # about 75% of the data\n",
    "num_test = num_all - num_train\n",
    "\n",
    "# select features (X) and corresponding labels (y) for the training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# Shuffle and split the data\n",
    "def shuffle_split_data(train_set_size):  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = np.true_divide(num_test,num_all), train_size = train_set_size, random_state = 1)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = shuffle_split_data(300)\n",
    "print \"Training set: {} samples\".format(X_train.shape[0])\n",
    "print \"Test set: {} samples\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.016\n"
     ]
    }
   ],
   "source": [
    "# Choose a model, import it and instantiate an object\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 10)\n",
    "# Train a model\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print \"Training {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print \"Done!\\nTraining time (secs): {:.3f}\".format(end - start)\n",
    "\n",
    "\n",
    "# Fit model to training data\n",
    "train_classifier(clf, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.003\n",
      "F1 score for training set: 0.989847715736\n"
     ]
    }
   ],
   "source": [
    "# Predict on training set and compute F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print \"Predicting labels using {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print \"Done!\\nPrediction time (secs): {:.3f}\".format(end - start)\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "train_f1_score = predict_labels(clf, X_train, y_train)\n",
    "print \"F1 score for training set: {}\".format(train_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.728682170543\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "print \"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 Random Forst:\n",
    "- General Applications:\n",
    "    Random forests is an ensemble learning method for classification, regression and some other tasks.\n",
    "- Lengths:\n",
    "    1. It runs efficiently on large data bases. \n",
    "    2. Almost always have lower classification error and better f-scores than dicision trees.\n",
    "    3. Dealing really well with uneven data sets that have missing variables.\n",
    "    4. Generally train faster than SVMs.\n",
    "    5. Can handle very well high dimensional spaces.\n",
    "- Weaknesses:\n",
    "    1. Large number of trees may make the algorithm slow for real-time prediction.\n",
    "- Reason:\n",
    "    Random Forest is a general algorithm to considered when dealing with classification problem, also in this case, we should deal with hign dimensional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.008\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for training set: 0.96062992126\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.728682170543\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.012\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for training set: 0.988764044944\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.706766917293\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.012\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.003\n",
      "F1 score for training set: 0.99\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Train and predict using different training set sizes\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    print \"------------------------------------------\"\n",
    "    print \"Training set size: {}\".format(len(X_train))\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    print \"F1 score for training set: {}\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test))\n",
    "\n",
    "# size = 100\n",
    "X_train, y_train, X_test, y_test = shuffle_split_data(100)\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "# Note: Keep the test set constant\n",
    "\n",
    "# size = 200\n",
    "X_train, y_train, X_test, y_test = shuffle_split_data(200)\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# size = 300\n",
    "X_train, y_train, X_test, y_test = shuffle_split_data(300)\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Time (secs)</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction Time for Training Set (secs)</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction Time for Testing Set (secs)</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score for Training Set</th>\n",
       "      <td>0.960</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score for Testing Set</th>\n",
       "      <td>0.728</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           100    200    300\n",
       "Training Time (secs)                     0.008  0.012  0.012\n",
       "Prediction Time for Training Set (secs)  0.002  0.002  0.003\n",
       "Prediction Time for Testing Set (secs)   0.002  0.001  0.002\n",
       "F1 Score for Training Set                0.960  0.988  0.990\n",
       "F1 Score for Testing Set                 0.728  0.706  0.800"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [\"Training Time (secs)\", \"Prediction Time for Training Set (secs)\",\n",
    "        \"Prediction Time for Testing Set (secs)\", \"F1 Score for Training Set\",\n",
    "        \"F1 Score for Testing Set\"]\n",
    "results = {'100': [0.008, 0.002, 0.002, 0.960, 0.728],\n",
    "           '200': [0.012, 0.002, 0.001, 0.988, 0.706],\n",
    "           '300': [0.012, 0.003, 0.002, 0.990, 0.800]}\n",
    "\n",
    "pd.DataFrame(results, index = items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 Support Vector Machine:\n",
    "- General Applications:\n",
    "    Support vector machines are supervised learning models which used for classification and regression analysis.\n",
    "- Strengths:\n",
    "    1. Optimizes the classification error rather than the likelihood.\n",
    "    2. They work really well in complicated domains where there is a clear margin of separation.\n",
    "- Weaknesses:\n",
    "    1. They don't perform so well in very large data sets, because the training time happens to be cubic in the size of the data set\n",
    "    2. They don't work well with lots of noise, they might be prone to overfitting to some of the noise, so the class are very overlapping you have to count independent evidence, that's wehere then a naive bayes classifier would be better\n",
    "- Reason:\n",
    "    In this case, we have large amount of features, and the data set is not very large, so we choose SVM which can perform well in complicated domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.002\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for training set: 0.859060402685\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.833333333333\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.005\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.003\n",
      "F1 score for training set: 0.858064516129\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.84076433121\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.012\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.008\n",
      "F1 score for training set: 0.858387799564\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.003\n",
      "F1 score for test set: 0.846153846154\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train and predict using two other models\n",
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "\n",
    "# size = 100\n",
    "X_train, y_train, X_test, y_test = shuffle_split_data(100)\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# size = 200\n",
    "X_train, y_train, X_test, y_test = shuffle_split_data(200)\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# size = 300\n",
    "X_train, y_train, X_test, y_test = shuffle_split_data(300)\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Time (secs)</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction Time for Training Set (secs)</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction Time for Testing Set (secs)</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score for Training Set</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score for Testing Set</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           100    200    300\n",
       "Training Time (secs)                     0.002  0.005  0.012\n",
       "Prediction Time for Training Set (secs)  0.001  0.003  0.008\n",
       "Prediction Time for Testing Set (secs)   0.001  0.002  0.003\n",
       "F1 Score for Training Set                0.859  0.858  0.858\n",
       "F1 Score for Testing Set                 0.833  0.840  0.846"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [\"Training Time (secs)\", \"Prediction Time for Training Set (secs)\",\n",
    "        \"Prediction Time for Testing Set (secs)\", \"F1 Score for Training Set\",\n",
    "        \"F1 Score for Testing Set\"]\n",
    "results = {'100': [0.002, 0.001, 0.001, 0.859, 0.833],\n",
    "           '200': [0.005, 0.003, 0.002, 0.858, 0.840],\n",
    "           '300': [0.012, 0.008, 0.003, 0.858, 0.846]}\n",
    "\n",
    "pd.DataFrame(results, index = items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 Gradient Boosting:\n",
    "- General Applications:\n",
    "    Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models.\n",
    "- Strengths:\n",
    "    1. Can handle categorical features very well.\n",
    "    2. Can handle very well high dimensional spaces as well as large number of training examples.\n",
    "    3. Gradient Boosting will usually perform better compared to Random Forest.\n",
    "- Weaknesses:\n",
    "    1. Harder to get right compared to Random Forest, since Gradient Boosting have more hyper-parameters to tune and more prone to overfitting,\n",
    "- Reason:\n",
    "    This are categorical features and this is a classification problem, and we have large amount of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training GradientBoostingClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.027\n",
      "Predicting labels using GradientBoostingClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 0.984848484848\n",
      "Predicting labels using GradientBoostingClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.65\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training GradientBoostingClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.037\n",
      "Predicting labels using GradientBoostingClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 0.901098901099\n",
      "Predicting labels using GradientBoostingClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.772727272727\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training GradientBoostingClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.037\n",
      "Predicting labels using GradientBoostingClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for training set: 0.875305623472\n",
      "Predicting labels using GradientBoostingClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.776119402985\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "\n",
    "# size = 100\n",
    "X_train, y_train, X_test, y_test = shuffle_split_data(100)\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# size = 200\n",
    "X_train, y_train, X_test, y_test = shuffle_split_data(200)\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# size = 300\n",
    "X_train, y_train, X_test, y_test = shuffle_split_data(300)\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Time (secs)</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction Time for Training Set (secs)</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction Time for Testing Set (secs)</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score for Training Set</th>\n",
       "      <td>0.984</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score for Testing Set</th>\n",
       "      <td>0.650</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           100    200    300\n",
       "Training Time (secs)                     0.027  0.037  0.037\n",
       "Prediction Time for Training Set (secs)  0.000  0.000  0.001\n",
       "Prediction Time for Testing Set (secs)   0.000  0.000  0.000\n",
       "F1 Score for Training Set                0.984  0.901  0.875\n",
       "F1 Score for Testing Set                 0.650  0.772  0.776"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [\"Training Time (secs)\", \"Prediction Time for Training Set (secs)\",\n",
    "        \"Prediction Time for Testing Set (secs)\", \"F1 Score for Training Set\",\n",
    "        \"F1 Score for Testing Set\"]\n",
    "results = {'100': [0.027, 0.000, 0.000, 0.984, 0.650],\n",
    "           '200': [0.037, 0.000, 0.000, 0.901, 0.772],\n",
    "           '300': [0.037, 0.001, 0.000, 0.875, 0.776]}\n",
    "\n",
    "pd.DataFrame(results, index = items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Model\n",
    "    \n",
    "The best model in this example is Support Vector Machine. Comparing the Training time: Gradient Boosting takes longer time than Random Forest and Support Vector Machine. The F1 score of Random Forest and Gradient Boosting for Training Test is better than Support Vector Machine, however, the F1 score of Support Vector Machine is the best, so SVMs are harder to overfitting compared the other two models.\n",
    "\n",
    "So we chose SVMs as the best model, since the training time of SVMs are almost the same as Random Forest, but SVMs perform best on testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How the model chosen is supposed to work:\n",
    "\n",
    "This project is a classification problem, we are provided lots of features of students, such as ages, weekly study time and number of past class failures etc, we want to predict whether or not the student will pass the final exam based on these features.\n",
    "\n",
    "The best model we chose here is SVMs, what SVMs do is find a separating line between data of two classes. Suppose we have some data of two different classes, SVMs is an algorithm that takes this data as an input, and output a line that separates those classes. SVMs choose the line that maximizes the distance to the nearest points of either of two classes. So for SVMs, we are trying to find the separating line which classifies two classes correctly, and subject to that constraint, maximizes the distance between the nearest points from two classes.\n",
    "\n",
    "In this example, we have lots information of students, we can classify them into two classes based on whether or not pass the final exam, we consider all students as two types of points in a plane, in the training process, we are trying to find lines that can correctly separate two classes of students, among all of these lines, we pick the one which maximizes the distances to the nearest points from two classes, then we finished training our data. In the predicting process, for example, if we know all features of a new student, we can locate this student as a point in the plane, then what we need to do is to check which side of the separating line this student located, we will predict the students as the same class as other points in that side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the grid search: \n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
      "  kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
      "  shrinking=True, tol=1e-05, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import svm, grid_search, datasets\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_train, y_train, X_test, y_test = shuffle_split_data(300)\n",
    "def f1_metrics(y_true, y_pred):\n",
    "    f1 = f1_score(y_true, y_pred, pos_label='yes')\n",
    "    return f1\n",
    "\n",
    "# grid serch\n",
    "def grid_search_SVM(X, y):\n",
    "    clf = SVC()\n",
    "    parameters = {'C':(0.001, 0.01, 1, 10, 100),\n",
    "                  'kernel': ('linear', 'poly', 'rbf','sigmoid'),\n",
    "                  'tol': (1e-5, 1e-4, 1e-3, 1e-2, 1e-1),\n",
    "                  'probability': (True, False)\n",
    "                 }\n",
    "    scoring_function = make_scorer(f1_metrics)\n",
    "    grid = grid_search.GridSearchCV(clf, parameters, scoring_function)\n",
    "    grid.fit(X, y)\n",
    "    return grid, grid.best_estimator_\n",
    "\n",
    "model, parameters = grid_search_SVM(X_train, y_train)\n",
    "print \"Parameters of the grid search: \"\n",
    "print parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using GridSearchCV...\n",
      "Done!\n",
      "Prediction time (secs): 0.010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85528455284552862"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_labels(model, X_all, y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The tuned parameters:\n",
    "- kernel = 'rbf'\n",
    "- C = 1\n",
    "- tol = 1e-5\n",
    "- probability = True\n",
    "\n",
    "F1 score of tuned model on entire training set:\n",
    "F1 score = 0.855, which is better than the F1 score(0.846) before tuning parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
